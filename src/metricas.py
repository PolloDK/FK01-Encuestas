import pandas as pd
from datetime import datetime, timedelta
from wordcloud import WordCloud
import matplotlib.pyplot as plt
import os
import re
from tqdm import tqdm
from src.config import PROCESSED_DATA_PATH, WORDCLOUD_PATH, PREDICTIONS_PATH, FEATURES_DATASET_PATH
from src.logger import get_logger
logger = get_logger(__name__, "metricas.log")

def clasificar_sentimiento(row):
    scores = {
        "positivo": row["score_positive"],
        "negativo": row["score_negative"],
        "neutro": row["score_neutral"]
    }
    max_score = max(scores.values())

    # Manejo de empates: si hay m√°s de un score con el mismo valor m√°ximo
    candidatos = [k for k, v in scores.items() if v == max_score]
    if len(candidatos) > 1:
        return "neutro"  # asignamos neutro en caso de empate
    return candidatos[0]

def calcular_metricas():
    logger.info("Iniciando c√°lculo de m√©tricas")

    try:
        df_pred = pd.read_csv(PREDICTIONS_PATH, parse_dates=["date"])
        logger.info("Archivo de predicciones cargado.")
    except Exception as e:
        logger.error(f"No se pudo cargar predicciones_diarias.csv: {e}")
        return

    try:
        df_features = pd.read_csv(FEATURES_DATASET_PATH, parse_dates=["date"])
        negatividad_por_dia = df_features.groupby(df_features['date'].dt.date)['score_negative'].mean().reset_index()
        negatividad_por_dia.columns = ['date', 'indice_negatividad']
        negatividad_por_dia["date"] = pd.to_datetime(negatividad_por_dia["date"])
        logger.info("√çndice de negatividad calculado.")
    except Exception as e:
        logger.error(f"Error en c√°lculo de √≠ndice de negatividad: {e}")
        return

    try:
        df_raw = pd.read_csv(PROCESSED_DATA_PATH, parse_dates=["createdAt"])
        df_raw = df_raw.dropna(subset=["score_positive", "score_negative", "score_neutral"])
        df_raw["date_only"] = df_raw["createdAt"].dt.date
        df_raw["sentimiento_clasificado"] = df_raw.apply(clasificar_sentimiento, axis=1)

        conteos = df_raw.groupby("date_only")["sentimiento_clasificado"].value_counts().unstack(fill_value=0).reset_index()
        conteos.columns.name = None
        conteos = conteos.rename(columns={
            "date_only": "date",
            "negativo": "tweets_negativos",
            "positivo": "tweets_positivos",
            "neutro": "tweets_neutros"
        })
        conteos["total_tweets"] = conteos[["tweets_negativos", "tweets_positivos", "tweets_neutros"]].sum(axis=1)
        conteos["porcentaje_tweets_negativos"] = conteos["tweets_negativos"] / conteos["total_tweets"]
        conteos["date"] = pd.to_datetime(conteos["date"])
        logger.info("Porcentaje de tweets negativos calculado.")
    except Exception as e:
        logger.error(f"Error en c√°lculo de % tweets negativos: {e}")
        return

    try:
        df_metricas = pd.merge(negatividad_por_dia, conteos, on="date", how="outer")
        df_actualizado = pd.merge(df_pred, df_metricas, on="date", how="left")
        df_actualizado.to_csv(PREDICTIONS_PATH, index=False, date_format="%Y-%m-%d")
        logger.info("Archivo de predicciones_diarias.csv actualizado con m√©tricas.")
    except Exception as e:
        logger.error(f"Error al actualizar archivo final: {e}")
        
def generar_wordcloud_diario():
    today = datetime.today().date()
    generar_wordcloud_para_fecha(today)


def generar_wordcloud_para_fecha(target_date):
    os.makedirs(WORDCLOUD_PATH, exist_ok=True)

    df = pd.read_csv(PROCESSED_DATA_PATH, parse_dates=["createdAt"])
    if "createdAt" not in df.columns or "text" not in df.columns:
        logger.warning("El archivo no tiene las columnas requeridas: createdAt y text")
        return

    df["createdAt"] = pd.to_datetime(df["createdAt"], errors='coerce')
    df = df.dropna(subset=["createdAt", "text"])
    df_target = df[df["createdAt"].dt.date == target_date]

    if df_target.empty:
        logger.warning(f"No hay tweets disponibles para {target_date}")
        return

    text = " ".join(df_target["text"].dropna().astype(str))
    # üîç Lista de palabras o frases a eliminar (convertidas a min√∫sculas)
    frases_excluir = ["gabriel boric", "presidente boric"]
    palabras_excluir = ["boric", "gabriel", "presidente", "chile"]

    # Eliminar frases primero
    for frase in frases_excluir:
        text = text.replace(frase, "")

    # Eliminar palabras individuales usando regex con l√≠mites de palabra
    for palabra in palabras_excluir:
        text = re.sub(rf"\b{re.escape(palabra)}\b", "", text)

    wordcloud = WordCloud(
        width=800, height=400,
        background_color='white',
        colormap='plasma',
        max_words=200
    ).generate(text)

    output_path = os.path.join(WORDCLOUD_PATH, f"wordcloud_{target_date}.png")
    wordcloud.to_file(output_path)
    logger.info(f"Wordcloud generado: {output_path}")


def generar_wordclouds_historicos():
    df = pd.read_csv(PROCESSED_DATA_PATH, parse_dates=["createdAt"])
    df = df.dropna(subset=["createdAt", "text"])
    dias_unicos = df["createdAt"].dt.date.unique()

    for i, fecha in enumerate(tqdm(sorted(dias_unicos), desc="Wordclouds")):
        generar_wordcloud_para_fecha(fecha)


def main():
    #calcular_metricas()
    #generar_wordcloud_diario()
    generar_wordclouds_historicos()  # Ejecuta solo si quieres correr todos

if __name__ == "__main__":
    main()
