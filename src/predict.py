import pandas as pd
import joblib
import numpy as np
from pathlib import Path
from src.azure_blob import read_csv_blob, write_csv_blob
from src.azure_blob import download_blob
from config import FEATURES_DATASET_PATH, MODEL_DIR, PREDICTIONS_PATH
from logger import get_logger

logger = get_logger(__name__, "predict.log")

class Predictor:
    def __init__(self, features_path=FEATURES_DATASET_PATH, model_dir=MODEL_DIR):
        self.features_path = Path(features_path)
        self.model_dir = Path(model_dir)
        # === Aprobaci√≥n ===
        self.aprobacion_bundle = self._load_model("modelo_aprobacion.pkl")
        # === Desaprobaci√≥n ===
        self.desaprobacion_bundle = self._load_model("modelo_desaprobacion.pkl")

    def _load_model(self, filename):
        path = self.model_dir / filename
        if not path.exists():
            print(f"üì• Modelo {filename} no encontrado localmente. Descargando desde Azure...")
            try:
                download_blob(f"models/{filename}", str(path))
            except Exception as e:
                logger.error(f"‚ùå Error al descargar modelo desde Azure: {e}")
                return None

    def predict(self):
        print("üöÄ Entrando a m√©todo `predict()`")
        try:
            df = read_csv_blob(str(self.features_path))
            if df.empty or df.shape[0] == 0 or df.shape[1] == 0:
                logger.warning(f"‚ö†Ô∏è El archivo {self.features_path} fue cargado pero est√° vac√≠o.")
                return pd.DataFrame()
            logger.info(f"‚úÖ Features cargados desde {self.features_path}: {df.shape}")
            print(f"‚úÖ Features cargados: {df.shape}")
        except Exception as e:
            logger.error(f"‚ùå No se pudo cargar el archivo de features: {e}")
            print(f"‚ùå ERROR leyendo features_dataset.csv: {e}")
            return pd.DataFrame()

        resultados = pd.DataFrame()

        # === Predicci√≥n de aprobaci√≥n ===
        if self.aprobacion_bundle:
            try:
                df_aprob = df.copy()
                
                # Obtengo los nombres de las features, el modelo y los scalers a utilizar:
                feature_names = self.aprobacion_bundle["feature_names"]
                model = self.aprobacion_bundle.get("model")
                scaler_X = self.aprobacion_bundle.get("scaler_X", None)
                scaler_y = self.aprobacion_bundle.get("scaler_y", None)
                
                #if self.aprobacion_bundle:
                #    print("‚úÖ Validaci√≥n bundle:")
                #    print("Features seleccionadas:", self.aprobacion_bundle.get("feature_names"))
                #    print("Modelo entrenado:", model)
                #    print("üîç Bundle keys:", self.aprobacion_bundle.keys())

                # Asegura que la columna date est√© en formato reconocible de fecha
                df_aprob["date"] = pd.to_datetime(df_aprob["date"], errors="coerce")

                # Asegura que todas las columnas requeridas est√©n en el dataset
                missing_cols = [col for col in feature_names if col not in df_aprob.columns]
                if missing_cols:
                    logger.error(f"‚ùå Faltan columnas en el DataFrame para predicci√≥n de aprobaci√≥n: {missing_cols}")
                    return resultados


                # Construimos X y filtramos NaNs
                X_aprob_raw = df_aprob[feature_names]
                #print(X_aprob_raw.tail(10))
                #print("üìä Total de NaNs por columna:")
                #print(X_aprob_raw.isna().sum().sort_values(ascending=False))
                logger.info(f"üîç Filas antes de filtrar NaNs (aprobaci√≥n): {X_aprob_raw.shape[0]}")
                mask_notna = X_aprob_raw.notna().all(axis=1)
                X_aprob_raw = X_aprob_raw[mask_notna]
                #print("üß™ Columnas en X_aprob_raw:", X_aprob_raw.columns.tolist())
                #print(X_aprob_raw.tail(10))
                df_aprob = df_aprob.loc[X_aprob_raw.index].copy()
                logger.info(f"üßπ Filas despu√©s de filtrar NaNs (aprobaci√≥n): {X_aprob_raw.shape[0]}")
                
                #print("üß™ Columnas en X_aprob_raw:")
                #print(X_aprob_raw.columns.tolist())
                #print("üìå Columnas que espera el modelo:")
                #print(feature_names)

                if X_aprob_raw.empty:
                    logger.warning("‚ö†Ô∏è No hay suficientes datos para predecir aprobaci√≥n.")
                    return resultados

                X_aprob_scaled = scaler_X.transform(X_aprob_raw)
                y_aprob_scaled = model.predict(X_aprob_scaled)
                y_aprob = (
                    scaler_y.inverse_transform(y_aprob_scaled.reshape(-1, 1)).flatten()
                    if scaler_y else y_aprob_scaled
                )
                
                # Guardar resultados
                df_aprob_result = df_aprob[["date"]].copy()
                df_aprob_result["prediccion_aprobacion"] = y_aprob
                resultados = (
                    df_aprob_result if resultados.empty
                    else resultados.merge(df_aprob_result, on="date", how="outer")
                )
                logger.info(f"üìà Predicciones de aprobaci√≥n generadas: {len(y_aprob)}")

            except Exception as e:
                logger.error(f"‚ùå Error al predecir aprobaci√≥n: {e}")

        # === Predicci√≥n de desaprobaci√≥n ===
        if self.desaprobacion_bundle:
            try:
                df_desaprob = df.copy()

                feature_names = self.desaprobacion_bundle["feature_names"]
                model = self.desaprobacion_bundle.get("model")
                scaler_X = self.desaprobacion_bundle.get("scaler_X", None)
                scaler_y = self.desaprobacion_bundle.get("scaler_y", None)

                #print("‚úÖ Validaci√≥n bundle (desaprobaci√≥n):")
                #print("Features seleccionadas:", feature_names)
                #print("Modelo entrenado:", model)
                #print("üîç Bundle keys:", self.desaprobacion_bundle.keys())

                df_desaprob["date"] = pd.to_datetime(df_desaprob["date"], errors="coerce")

                missing_cols = [col for col in feature_names if col not in df_desaprob.columns]
                if missing_cols:
                    logger.error(f"‚ùå Faltan columnas en el DataFrame para desaprobaci√≥n: {missing_cols}")
                    return resultados

                X_desaprob_raw = df_desaprob[feature_names]
                logger.info(f"üîç Filas antes de filtrar NaNs (desaprobaci√≥n): {X_desaprob_raw.shape[0]}")
                X_desaprob_raw = X_desaprob_raw.dropna()
                df_desaprob = df_desaprob.loc[X_desaprob_raw.index].copy()
                logger.info(f"üßπ Filas despu√©s de filtrar NaNs (desaprobaci√≥n): {X_desaprob_raw.shape[0]}")

                #print("üß™ Columnas en X_desaprob_raw:")
                #print(X_desaprob_raw.columns.tolist())
                #print("üìå Columnas que espera el modelo:")
                #print(feature_names)

                if X_desaprob_raw.empty:
                    logger.warning("‚ö†Ô∏è No hay suficientes datos para predecir desaprobaci√≥n.")
                    return resultados

                # Escalamiento
                X_desaprob_scaled = scaler_X.transform(X_desaprob_raw)

                # Predicci√≥n
                y_desaprob_scaled = model.predict(X_desaprob_scaled)
                y_desaprob = (
                    scaler_y.inverse_transform(y_desaprob_scaled.reshape(-1, 1)).flatten()
                    if scaler_y else y_desaprob_scaled
                )
                #print("üîç scaler_y center_:", getattr(scaler_y, "center_", "N/A"))
                #print("üîç scaler_y scale_:", getattr(scaler_y, "scale_", "N/A"))
                #print("üîç y_desaprob_scaled (sample):", y_desaprob_scaled[:5])
                #print("üîç y_desaprob inverso (sample):", y_desaprob[:5])
                #print("üîÅ Predicciones desaprobaci√≥n (√∫ltimos 5):", y_desaprob[-5:])
                #print("üìÖ Fechas predichas:", df_desaprob["date"].tail().tolist())
                #print("üéØ Escala predicha (antes de inversa):", y_desaprob_scaled[:5])
                #print("üéØ Escala final (despu√©s de inversa):", y_desaprob[:5])
                df_desaprob_result = df_desaprob[["date"]].copy()
                df_desaprob_result["prediccion_desaprobacion"] = y_desaprob

                resultados = (
                    df_desaprob_result if resultados.empty
                    else resultados.merge(df_desaprob_result, on="date", how="outer")
                )
                logger.info(f"üìâ Predicciones de desaprobaci√≥n generadas: {len(y_desaprob)}")

            except Exception as e:
                logger.error(f"‚ùå Error al predecir desaprobaci√≥n: {e}")



        if resultados.empty:
            logger.warning("No se generaron predicciones. Guardando CSV vac√≠o con columnas.")
            return pd.DataFrame(columns=["date", "prediccion_aprobacion", "prediccion_desaprobacion"])

        return resultados.sort_values("date")

if __name__ == "__main__":
    
    predictor = Predictor()
    resultados = predictor.predict()

    if resultados.empty:
        logger.warning("No se generaron predicciones. Guardando CSV vac√≠o con columnas.")
        resultados = pd.DataFrame(columns=["date", "prediccion_aprobacion", "prediccion_desaprobacion"])

    print(f"üíæ Guardando archivo en: {PREDICTIONS_PATH}")
    write_csv_blob(resultados, PREDICTIONS_PATH)
    print(f"üìà Predicci√≥n guardada en {PREDICTIONS_PATH}")